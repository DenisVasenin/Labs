#data_q = quantile(data, probs = seq(0, 1, 0.25))
#round(data_q, 2)
#summary(data)
# Выбираем интервалы
k = 4    # число интервалов
x_br = c(0, 1, 2, 3)
# Вычисляем фактические частоты
count = as.vector(table(data))
dens = count/length(data)
#qqnorm(data)
# Вычисляем по выборке теоретические вероятности для каждого интервала
# раздвигаем границы до бесконечности
x_br[1] = (-Inf)
x_br[k + 1] = (+Inf)
data_theor = pnorm(x_br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
round(data_theor, 2)
x <- seq(0, 3,by = 1)
y = pnorm(x, mean = mean(data), sd = sd(data))
#y <- dnorm(x)
plot(x, y)
# Сравниваем фактические и теоретические частоты
chisq.test(dens, p = data_theor)
ll = hist(data, right = FALSE)
ll = hist(data, breaks = 0:4, right = FALSE)
density(data)
??lines
# Chunk 1
library(ggplot2)
# Chunk 2
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
data
# Chunk 3
#count = as.matrix(table(data))
#dens = count/length(data)
# Chunk 4
#ggplot() + geom_density(aes(data), adjust = 2)
#ggplot() + geom_bar(aes(data))
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
lines(density(data))
# Chunk 5
#Вычисляем квантили выборки с шагом 10% по 10 элементов в интервале
#data_q = quantile(data, probs = seq(0, 1, 0.25))
#round(data_q, 2)
#summary(data)
# Выбираем интервалы
k = 4                                                   # число интервалов
x_br = c(0, 1, 2, 3)
# Вычисляем фактические частоты
count = as.vector(table(data))
dens = count/length(data)
# Вычисляем по выборке теоретические вероятности для каждого интервала
# раздвигаем границы до бесконечности
x_br[1] = (-Inf)
x_br[k + 1] = (+Inf)
data_theor = pnorm(x_br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
round(data_theor, 2)
x <- seq(0, 3,by = 1)
y = pnorm(x, mean = mean(data), sd = sd(data))
#y <- dnorm(x)
plot(x, y)
# Сравниваем фактические и теоретические частоты
chisq.test(dens, p = data_theor)
data_theor = pnorm(x_br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
round(data_theor, 2)
# Chunk 1
library(ggplot2)
# Chunk 2
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
data
# Chunk 3
#ggplot() + geom_density(aes(data), adjust = 2)
#ggplot() + geom_bar(aes(data))
#count = as.matrix(table(data))
#dens = count/length(data)
# Chunk 4
# Выбираем интервалы
k = 4
br = c(0, 1, 2, 3)
# Вычисляем фактические частоты
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
lines(density(data))
# Вычисляем по выборке теоретические вероятности для каждого интервала
br[1] = (-Inf)
br[k + 1] = (+Inf)
data_theor = pnorm(br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
round(data_theor, 2)
# Сравниваем фактические и теоретические частоты
chisq.test(h$counts, p = data_theor)
data_theor = pnorm(br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
br = c(0, 1, 2, 3)
br = c(-Inf, br, + Inf)
br
# Chunk 1
library(ggplot2)
# Chunk 2
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
data
# Chunk 3
#ggplot() + geom_density(aes(data), adjust = 2)
#ggplot() + geom_bar(aes(data))
#count = as.matrix(table(data))
#dens = count/length(data)
# Chunk 4
# Выбираем интервалы
k = 4
br = c(0, 1, 2, 3)
# Вычисляем фактические частоты
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
lines(density(data))
# Вычисляем по выборке теоретические вероятности для каждого интервала
br = c(-Inf, br, + Inf)
#br[k + 1] = (+Inf)
data_theor = pnorm(br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
round(data_theor, 2)
# Сравниваем фактические и теоретические частоты
chisq.test(h$counts, p = data_theor)
data_theor = pnorm(br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
round(data_theor, 2)
data_theor = pnorm(br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
data_theor = pnorm(br, mean = mean(data), sd = sd(data))
data_theor
rnorm(132, mean = mean(data), sd = sd(data))
??rnorm
# Chunk 1
library(ggplot2)
# Chunk 2
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
data
# Chunk 4
norm <- quantile(data, probs = seq(0, 1, 0.25))
round(norm, 2)
pnorm(norm, mean = mean(data), sd = sd(data))
# Выбираем интервалы
k = 4
br = c(0, 1, 2, 3)
# Вычисляем фактические частоты
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
lines(density(data))
# Вычисляем по выборке теоретические вероятности для каждого интервала
br = c(-Inf, br, +Inf)
#br[k + 1] = (+Inf)
data_theor = pnorm(br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
round(data_theor, 2)
# Сравниваем фактические и теоретические частоты
chisq.test(h$counts, p = data_theor)
plot(density(data))
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
plot(density(data))
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
h = hist(data, breaks = 0:3, right = FALSE, freq = FALSE)
lines(density(data))
plot(density(data))
den = density(data)
??density
den = density(data, bw = 1)
den = density(data, bw = 2)
den = density(data, bw = 1, kernel = "gaussian")
den = density(data, n = 4)
den = density(data, from = 0, to = 3)
den = density(data, from = 0, to = 3, n = 4)
plot(den)
plot(density(data))
??par
par(mfrow = c(2, 2))
den = density(data, from = 0, to = 3, n = 4)
plot(density(data))
par(mfrow = c(2, 2))
den = density(data, from = 0, to = 3, n = 4)
plot(density(data))
den = density(data, from = 0, to = 3, n = 4)
h = hist(data, breaks = 0:3, right = FALSE, freq = FALSE)
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
den = density(data, from = 0, to = 3, n = 4, bw = 1)
plot(density(data))
den = density(data, from = 0, to = 3, n = 4, bw = 1)
plot(density(data))
den = density(data, from = 0, to = 3, n = 4, bw = 1)
plot(density(data))
den = density(data, from = 0, to = 3, n = 4)
plot(density(den))
plot(density(data))
plot(density(den))
plot(den)
plot(density(data))
132 * 0.729
132 * 0.0717
132 * 0.0455
den = density(data, from = 0, to = 3)
, n = 4
den = density(data, from = 0, to = 3, n = 4)
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
# Chunk 1
library(ggplot2)
# Chunk 2
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
data
# Chunk 3
# Выбираем интервалы
k = 4
br = c(0, 1, 2, 3)
# Вычисляем фактические частоты
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
# Вычисляем по выборке теоретические вероятности для каждого интервала
br = c(-Inf, br, +Inf)
#br[k + 1] = (+Inf)
data_theor = pnorm(br, mean = mean(data), sd = sd(data))
data_theor = (data_theor[2:(k + 1)] - data_theor[1:k])
round(data_theor, 2)
# Сравниваем фактические и теоретические частоты
#chisq.test(h$counts, p = data_theor)
h$breaks = c(0, 1, 2, 3)
h$mids = c(0, 1, 2, 3)
plot(h)
br
n = length(data)
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE)
??barplot
h = barplot(data, breaks = 0:4, right = FALSE, freq = FALSE)
h = barplot(data, right = FALSE, freq = FALSE)
h = barplot(data)
qq = rle(data)
qq
unique(data)
??unique
duplicated(data)
h = hist(data)
??hist
h = hist(data, breaks = c(0,1,2,3))
h = hist(data, breaks = c(0,1,2,3,4))
h = hist(data, breaks = c(0,1,2,3,4), freq = TRUE)
h = hist(data, breaks = c(0,1,2,3,4))
barplot(h$counts, width = c(0,1,2,3,4))
barplot(h$counts)
barplot(h$counts, width = 0)
barplot(h$counts, width = 1)
barplot(h$counts, width = 0.5)
barplot(h$counts, space = 0)
barplot(h$counts, space = 0, names.arg = c(0, 1, 2, 3))
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE, plot = FALSE)
barplot(h$counts, space = 0, names.arg = c(0, 1, 2, 3))
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE, plot = FALSE)
barplot(h$counts, space = 0, names.arg = c(0, 1, 2, 3))
n = length(data)
x_mean = mean(data)
lambda = x_mean
??e
??Constants
x_mean = round(mean(data), 2)
lambda = x_mean
x_mean = round(mean(data), 3)
lambda = x_mean
??round
x_mean = round(mean(data), digits = 3)
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
x_mean = round(mean(data), digits = 3)
x_mean = round(mean(data), 4)
x_mean = round(mean(data), 3)
n = length(data)
e = 2.7182
x_mean = round(mean(data), 4)
lambda = x_mean
??factorial
factorial(3)
factorial(4)
i = 0
P0 = (lambda ^ i * e ^ -lambda) / factorial(i)
P0 = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
PP = c()
for (i in 0:3) {
P = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
PP[i+1] = P
}
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
P
print(P)
for (i in 0:3) {
P[i + 1] = round(n * P[i + 1], 4)
}
for (i in 0:3) {
P[i + 1] = n * P[i + 1]
}
for (i in 0:3) {
P[i + 1] = n * P[i + 1]
}
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
n = length(data)
e = 2.7182
x_mean = round(mean(data), 4)
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
lambda = x_mean
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
PP = c()
for (i in 0:3) {
PP[i + 1] = n * P[i + 1]
}
for (i in 0:3) {
P[i + 1] = n * P[i + 1]
}
print(P)
h = hist(data, breaks = 0:4, right = FALSE, freq = FALSE, plot = FALSE)
df = data.frame(i = c(0:3), n_emp = h$counts, n_teor = P)
View(df)
df = data.frame(i = c(0:3), n_e = h$counts, n_t = P, ne_nt = n_e - n_t)
df = data.frame(i = c(0:3), n_e = h$counts, n_e = P, n_t = n_e - n_t)
df = data.frame(i = c(0:3), n_e = h$counts, n_t = P, n_t = h$counts - P)
df = data.frame(i = c(0:3), ne = h$counts, nt = P, (ne_nt) = h$counts - P, )
df = data.frame(i = c(0:3), ne = h$counts, nt = P, xi = (h$counts - P) ^ 2 / nt )
df = data.frame(i = c(0:3), ne = h$counts, nt = P, xi = (h$counts - P) ^ 2 / P )
df
x_mean = round(mean(data))
x_mean = round(mean(data), 4)
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i))
}
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
for (i in 0:3) {
P[i + 1] = n * P[i + 1]
}
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
for (i in 0:3) {
P[i + 1] = round(n * P[i + 1])
}
df = data.frame(i = c(0:3), ne = h$counts, nt = P, xi = (h$counts - P) ^ 2 / P )
df = data.frame(i = c(0:3), ne = h$counts, nt = P, tmp = (h$counts - P) ^ 2 / P)
xi2 = df$tmp
xi2 = sum(df$tmp)
xi2 = round(sum(df$tmp), 4)
xi2_nabl = round(sum(df$tmp), 4)
# Chunk 1
library(ggplot2)
# Chunk 2
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
data
# Chunk 3
h = hist(data, breaks = 0:4, right = FALSE, plot = FALSE)
barplot(h$counts, space = 0, names.arg = c(0, 1, 2, 3))
# Параметры для расчетов
n = length(data)
e = 2.7182
k = 4 - 2
a = 0.05
xi_krit = 6
# Найдем выборочное среднее
x_mean = round(mean(data), 4)
# Примем в качестве оценки параметра lambda распределения Пуассона выборочную среднюю
lambda = x_mean
# Найдем по формуле Пуассона ( P(i) = (lambda^i * e^-lambda) / i! ) вероятности появления ровно i событий в n испытаниях (i = 0, 1, ... , r , где r - максимальное число наблюдавшихся событий, n - обьем выборки)
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
print(P)
# Найдем теоретические частоты по формуле n(i) = n * P(i)
for (i in 0:3) {
P[i + 1] = round(n * P[i + 1])
}
print(P)
# Сравнить эмпирические и теоретические частоты с помощью критерия Пирсона, приняв число степеней свободы k = s - 2 , где s - число различных групп выборки.
df = data.frame(i = c(0:3), ne = h$counts, nt = P, tmp = (h$counts - P) ^ 2 / P)
xi_nabl = round(sum(df$tmp), 2)
xi_nabl
h[1:3,]
h[,1]
h$breaks[1:3]
h$breaks[1:4]
61+53+12+6
??data.frame
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
h = hist(data, breaks = 0:4, right = FALSE, plot = FALSE)
h$counts
barplot(h$counts, space = 0, names.arg = c(0, 1, 2, 3))
# Параметры для расчетов
n = length(data)
e = 2.7182
k = 4 - 2
a = 0.05
xi_krit = 6
# Найдем выборочное среднее
x_mean = round(mean(data), 4)
# Примем в качестве оценки параметра lambda распределения Пуассона выборочную среднюю
lambda = x_mean
# Найдем по формуле Пуассона ( P(i) = (lambda^i * e^-lambda) / i! )
# вероятности появления ровно i событий в n испытаниях
# (i = 0, 1, ... , r , где r - максимальное число наблюдавшихся событий, n - обьем выборки)
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
print(P)
# Найдем теоретические частоты по формуле n(i) = n * P(i)
for (i in 0:3) {
P[i + 1] = round(n * P[i + 1])
}
print(P)
# Сравнить эмпирические и теоретические частоты с помощью критерия Пирсона,
# приняв число степеней свободы k = s - 2 , где s - число различных групп выборки.
df = data.frame(i = c(0:3), ne = h$counts, nt = P, tmp = (h$counts - P) ^ 2 / P)
xi_nabl = round(sum(df$tmp), 2)
xi_nabl
xi_krit
ww = round(sum(h$counts - P) ^ 2 / P)
ww = round(sum((h$counts - P) ^ 2 / P))
ww = sum((h$counts - P) ^ 2 / P)
ww = round(sum((h$counts - P) ^ 2 / P), 2)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
data = c(0,0,1,2,1,1,1,0,0,0,2,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,2,0,1,0,1,0,0,1,
1,1,1,0,0,1,1,1,0,2,0,1,0,1,0,0,0,0,0,1,3,0,1,2,2,0,0,1,0,3,1,1,1,1,1,1,
2,1,0,0,1,0,0,1,1,0,0,1,3,1,0,0,0,1,1,1,1,2,1,0,0,0,0,1,2,1,2,0,1,0,3,0,
1,0,1,0,3,1,0,3,0,0,1,2,0,0,1,0,0,1,1,1,1,0,2,0)
h = hist(data, breaks = 0:4, right = FALSE, plot = FALSE)
h$counts
barplot(h$counts, space = 0, names.arg = c(0, 1, 2, 3))
# Параметры для расчетов
n = length(data)
e = 2.7182
k = 4 - 2
a = 0.05
xi_krit = 6
# Найдем выборочное среднее
x_mean = round(mean(data), 4)
# Примем в качестве оценки параметра lambda распределения Пуассона выборочную среднюю
lambda = x_mean
# Найдем по формуле Пуассона ( P(i) = (lambda^i * e^-lambda) / i! )
# вероятности появления ровно i событий в n испытаниях
# (i = 0, 1, ... , r , где r - максимальное число наблюдавшихся событий, n - обьем выборки)
P = c()
for (i in 0:3) {
P[i + 1] = round((lambda ^ i * e ^ -lambda) / factorial(i), 4)
}
print(P)
# Найдем теоретические частоты по формуле n(i) = n * P(i)
for (i in 0:3) {
P[i + 1] = round(n * P[i + 1])
}
print(P)
# Сравнить эмпирические и теоретические частоты с помощью критерия Пирсона,
# приняв число степеней свободы k = s - 2 , где s - число различных групп выборки.
xi_nabl = round(sum((h$counts - P) ^ 2 / P), 2)
xi_nabl
xi_krit
qchisq(a, k)
qchisq(1-a, k)
qchisq(1-a, 1)
qchisq(1-a, k)
chisq.test(data)
